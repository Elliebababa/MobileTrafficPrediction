{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.sparse\n",
    "from scipy.sparse import *\n",
    "from scipy.sparse import linalg\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import collections\n",
    "import os, time, collections, shutil\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "helper function is included at the last of this page, including\n",
    "- showTime(timeInterval)\n",
    "- dataMatrix(timeInterval,data)\n",
    "- plotInternet(seriesList, nrows, ncols)\n",
    "- showNonzero(interaction)\n",
    "- showDistribution(interaction)\n",
    "- make_dataset(str_time,end_time) return list of tuple(x,adj) per time interval\n",
    "- adj_to_sym(interaction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data and preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Internet data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names = ['squareId','timeInterval','countryCode','smsIn','smsOut','callIn','callOut','Internet']\n",
    "dir_ = '../data/raw/milan/sms-call-internet-mi/sms-call-internet-mi-Nov/sms-call-internet-mi-2013-11-03.txt'\n",
    "data = pd.read_table(dir_,names = names)\n",
    "data = data.fillna(0)\n",
    "d = data.groupby(['squareId','timeInterval']).sum()\n",
    "d = d.drop(['countryCode'],axis = 1)\n",
    "str_time = min(d.index.get_level_values(1))\n",
    "end_time = max(d.index.get_level_values(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interaction data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "interaction =  load_npz('demo/1383464400000.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52.0"
      ]
     },
     "execution_count": 723,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1383464400000 - str_time)/600000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-89400000"
      ]
     },
     "execution_count": 719,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1383343800000 - str_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d = |V| = 10000,k|V| < |E| = 115\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAR0AAAD+CAYAAAAHzdHjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMnQkdWXoSOrK0JHU1f8DcPHL7ae82K0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d7015d0fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "showNonzero(interaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variance:  4.2047475e-05\n",
      "mean:  0.0011537509\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSWrQ/wM3B3pcv5CJsAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d709e14e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "showDistribution(interaction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57.0"
      ]
     },
     "execution_count": 725,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1383467400000 - str_time)/600000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making dataset from ../../notebook/demo\n",
      "finish preparing the dataset....\n"
     ]
    }
   ],
   "source": [
    "begin_time = str_time#1383467400000#str_time\n",
    "period = 600000 * 10\n",
    "X = make_dataset(begin_time,begin_time+period,d,'../../notebook/demo',64) \n",
    "#X = make_dataset(st,st+600000*10,d,64) # X include internet data and the adj graph\n",
    "XX = list(list(zip(*X))[0])\n",
    "ADJ = list(list(zip(*X))[1])\n",
    "XXX = list(zip(XX,ADJ))\n",
    "for t,i in enumerate(XX):\n",
    "    tmp = ((i - np.mean(i))/np.std(i))\n",
    "    XX[t] = tmp\n",
    "data_y = XX[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gcn package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**buil graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def list_of_csr_to_sparse_tensor(adjs):\n",
    "    # a little bug here\n",
    "    # I saved the csr matrix in the shape of 10001 * 10001\n",
    "    # and I convert back to 10000 * 10000 csr sparse tensor\n",
    "    # sorry for the careless operation...\n",
    "    indices = []\n",
    "    data = []\n",
    "    shape0 = len(adjs)\n",
    "    shape1,shape2 = adjs[0].shape\n",
    "    shape1 -= 1\n",
    "    shape2 -= 1\n",
    "    for i in range(shape0):\n",
    "        adj = adjs[i].toarray()\n",
    "        adj = scipy.sparse.coo_matrix(adj[1:,1:])\n",
    "        \n",
    "        row = adj.row\n",
    "        print('row',(row))\n",
    "        col = adj.col\n",
    "        print('col',(col))\n",
    "        idx = np.ones(row.shape, dtype = np.int32)*i\n",
    "        indx = list(zip(idx, row, col))\n",
    "        indices += indx\n",
    "        data += list(adj.data)\n",
    "    if indices == []:\n",
    "        indices = [[0,0,0],]\n",
    "        data = [0.,]\n",
    "    #indices = np.transpose(indices)\n",
    "    #eturn tf.SparseTensor(indices = indices, values = data, dense_shape = (shape0,shape1,shape2))\n",
    "    return indices,data#,[shape0,shape1,shape2]\n",
    "    #return tf.SparseTensorValue(indices = indices, values = data, dense_shape = [shape0,shape1,shape2])\n",
    "    #rint(shape0,shape1,shape2)\n",
    "    #eturn (np.array(indices),np.array(data),np.array([shape0,shape1,shape2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tt = tf.SparseTensor([[0,0,0]],[0],[1,1000,1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class st_cgcnn(base_model):\n",
    "    def __init__(self, F, K, M,num_epochs=20, learning_rate=0.1, decay_rate=0.95, decay_steps=None, momentum=0.9,batch_size=1, eval_frequency=20,\n",
    "                dir_name=''):\n",
    "        super().__init__()\n",
    "        #M denote the number of nodes in the graph\n",
    "        self.M, self.F, self.K = M,F,K\n",
    "        self.num_epochs, self.learning_rate = num_epochs, learning_rate\n",
    "        self.decay_rate, self.decay_steps, self.momentum = decay_rate, decay_steps, momentum\n",
    "        self.batch_size, self.eval_frequency = batch_size, eval_frequency\n",
    "        self.dir_name = dir_name\n",
    "        self.build_graph(M)\n",
    "    \n",
    "    def build_graph(self,M):\n",
    "        self.graph = tf.Graph()\n",
    "        self.M = M\n",
    "        with self.graph.as_default():\n",
    "            #Inputs\n",
    "            with tf.name_scope('inputs'):\n",
    "                self.data_x = tf.placeholder(tf.float32, (self.batch_size,M,self.F),'data_x')\n",
    "                self.data_adj = tf.sparse_placeholder(tf.float32,(self.batch_size, M, M),'data_adj')\n",
    "                #self.data_adj = tf.SparseTensor([[0,1,1]],np.repeat(2,100000000),[self.batch_size, M, M])\n",
    "                self.data_y = tf.placeholder(tf.float32,(self.batch_size,M),'data_y')\n",
    "            #Model\n",
    "            op_logits = self._inference(self.data_x,self.data_adj)\n",
    "            p = tf.Print(op_logits,[op_logits],'op_logits')\n",
    "            self.op_loss,self.op_loss_average = self.loss(p, self.data_y)\n",
    "            printout_loss = tf.Print(self.op_loss, [self.op_loss],'loss')\n",
    "            self.op_train = self.training(printout_loss, self.learning_rate, self.decay_steps, self.decay_rate, self.momentum)\n",
    "            self.op_prediction = self.prediction(op_logits)\n",
    "            \n",
    "            #initialize variables, i.e.. weights and biases\n",
    "            self.op_init = tf.global_variables_initializer()\n",
    "            \n",
    "            #summaries for tensorboard and save for model parameters\n",
    "            self.op_summary = tf.summary.merge_all()\n",
    "            self.op_saver = tf.train.Saver(max_to_keep = 5)\n",
    "        self.graph.finalize()\n",
    "        \n",
    "    def _inference(self,x,adj):\n",
    "            #Graph convolutional layer\n",
    "        #x = tf.expand_dims(x, 2) # N x M x F = 1, N is batch size\n",
    "            #we use one layer convolution here\n",
    "        with tf.variable_scope('conv1'):\n",
    "            with tf.name_scope('filter'):\n",
    "                x = self.filter_chebyshev(x,adj,1,K = 3) # return N x M x 1\n",
    "                p = tf.Print(x,[x],'conv1 filter: ')\n",
    "        return p   \n",
    "    \n",
    "    def laplacian(self, adj, normalized = True,sparse = True):\n",
    "        d = tf.reduce_sum(adj,axis = 0)\n",
    "        if not normalized:\n",
    "            D = tf.diag(d)\n",
    "            L = D - adj\n",
    "        else:\n",
    "            d += np.spacing(np.array(0))\n",
    "            d = 1 / tf.sqrt(d)\n",
    "            D = tf.diag(d)\n",
    "            I = tf.eye(tf.size(d))\n",
    "            L = I - D*adj*D\n",
    "            #upper bound on the spectrum\n",
    "            #lmax = linalg.eigsh(L,k = 1, which = 'LM', return_eigenvectors = False)[0]\n",
    "            #if normalized:\n",
    "            #    assert lmax <= 2\n",
    "            #    lmax = 2\n",
    "        return L\n",
    "    \n",
    "    def filter_chebyshev(self, x, adj, Fout = 1, K = 3):\n",
    "        #Filtering with chebyshev interpolation\n",
    "        #data : x of size N x M x F\n",
    "        #N: number of signals, i.e. number of time interval in our model\n",
    "        #M: number of vertices\n",
    "        #F: number of features per signal per vertex\n",
    "        #N,M,Fin = x.get_shape()\n",
    "        N,M,Fin = x.get_shape().as_list()\n",
    "        adj = tf.sparse_tensor_to_dense(adj,default_value = 0)\n",
    "        #for we have different adj matrix at every time Interval, thus we need to filter each signal seperately\n",
    "        for i in range(N):\n",
    "            sig = x[i] #1 x M x Fin\n",
    "            L = adj[i]#self.laplacian(adj[i])\n",
    "            #Rescale Laplacian \n",
    "            I = tf.eye(M)\n",
    "            lmax = 2 ##temporal\n",
    "            L /= lmax / 2\n",
    "            L -= I\n",
    "            #to Sparse Tensor\n",
    "            zero = tf.constant(0,dtype = tf.float32)\n",
    "            where  = tf.not_equal(L,zero)\n",
    "            indices = tf.where(where)\n",
    "            values = tf.gather_nd(L, indices)\n",
    "            L = tf.SparseTensor(indices, values, L.shape)\n",
    "            \n",
    "            #Transform to chebyshev basis\n",
    "            x0 = sig\n",
    "            x0 = tf.reshape(x0,[M,Fin]) #M x Fin \n",
    "            x = tf.expand_dims(x0,0) # 1 x M x Fin\n",
    "            def concat(x,x_,d = 0):\n",
    "                #print(tf.shape(x),tf.shape(x_))\n",
    "                x_ = tf.expand_dims(x_, d)\n",
    "                return tf.concat([x,x_],axis = d)\n",
    "            if K > 1:\n",
    "                x1 = tf.sparse_tensor_dense_matmul(L,x0)\n",
    "                x = concat(x,x1)\n",
    "            for k in range(2,K):\n",
    "                x2 = 2*tf.sparse_tensor_dense_matmul(L,x1) - x0\n",
    "                x = concat(x, x2)\n",
    "                x0,x1 = x1, x2\n",
    "            x = tf.reshape(x, [K,M,Fin]) # K x M x Fin\n",
    "            if i == 0:\n",
    "                x_all = tf.expand_dims(x, -1)\n",
    "            else:\n",
    "                x_all = concat(x_all,x,-1)\n",
    "            \n",
    "        x_all = tf.transpose(x_all, perm = [3,1,2,0]) #N x M x Fin x K    \n",
    "        x_all = tf.reshape(x_all, [N*M,Fin*K])\n",
    "                \n",
    "        #filter: Fin*Fout filter of order K, i.e. one filterbank per feature pair\n",
    "        W = self._weight_variable([Fin*K,Fout],regularization = False)\n",
    "        printout = tf.Print(W,[W],'W:')\n",
    "        x_all = tf.matmul(x_all,printout) # N*M  x Fout\n",
    "        return tf.reshape(x_all,[N,M])\n",
    "    \n",
    "    def loss(self, values, t_values):\n",
    "        # adds to the inference model the layers required to generate loss\n",
    "        with tf.name_scope('loss'):\n",
    "            with tf.name_scope('mse'):\n",
    "                mse = tf.square(values - t_values)\n",
    "                mse = tf.reduce_sum(values)\n",
    "                test = tf.reduce_sum(values)\n",
    "                #mse = tf.reduce_sum(mse)\n",
    "                #mse = tf.reduce_mean(mse)\n",
    "                print(values,t_values,mse)\n",
    "            loss = mse\n",
    "            \n",
    "        #summaries for tensorboard\n",
    "        tf.summary.scalar('loss/mse',mse)\n",
    "        with tf.name_scope('averages'):\n",
    "            #calculate the average loss up to now\n",
    "            averages = tf.train.ExponentialMovingAverage(0.9)\n",
    "            op_averages = averages.apply([mse])\n",
    "            tf.summary.scalar('loss/avg/total', averages.average(loss))\n",
    "            with tf.control_dependencies([op_averages]):\n",
    "                loss_average = tf.identity(averages.average(loss), name = 'control')\n",
    "        return loss, test#loss#_average\n",
    "\n",
    "    \n",
    "    def fit(self, train_data, train_y, val_data, val_y):\n",
    "        #process time\n",
    "        t_process, t_wall = time.process_time(), time.time()\n",
    "        sess = tf.Session(graph = self.graph)\n",
    "        #notice that x is of array form and adj is the list of csr\n",
    "        train_x,train_adj = train_data\n",
    "        val_x,val_adj = val_data\n",
    "        train_x = np.array(train_x)\n",
    "        train_adj = list(train_adj)\n",
    "        val_x = np.array(val_x)\n",
    "        val_adj = list(val_adj)\n",
    "        train_y = np.array(train_y)\n",
    "        val_y = np.array(val_y)\n",
    "        #print(type(train_x),type(train_adj),type(train_y))\n",
    "        #train_x,train_adj,train_y = list(train_x),list(train_adj),list(train_y)\n",
    "        #logging the fit information\n",
    "        shutil.rmtree(self._get_path('summaries'), ignore_errors = True)\n",
    "        writer = tf.summary.FileWriter(self._get_path('summaries'),self.graph)\n",
    "        shutil.rmtree(self._get_path('checkpoints'), ignore_errors = True)\n",
    "        os.makedirs(self._get_path('checkpoints'))\n",
    "        path = os.path.join(self._get_path('checkpoints'),'model')\n",
    "        sess.run(self.op_init)\n",
    "        #Training\n",
    "        losses = []\n",
    "        indices = collections.deque()\n",
    "        num_steps = int(self.num_epochs * train_x.shape[0]/self.batch_size)\n",
    "        for step in range(1, num_steps+1):\n",
    "            if len(indices) < self.batch_size:\n",
    "                indices.extend(np.random.permutation(train_x.shape[0]))\n",
    "            idx = [indices.popleft() for i in range(self.batch_size)]\n",
    "            batch_data_x = train_x[idx,...]\n",
    "            batch_data_adj = [train_adj[i] for i in idx]\n",
    "            batch_y = train_y[idx]\n",
    "            if (len(batch_y.shape) == 3):\n",
    "                batch_y = batch_y.squeeze(-1)\n",
    "            \n",
    "            #feed_dict = {self.data_x : batch_data_x, self.data_adj:list_of_csr_to_sparse_tensor(batch_data_adj), self.data_y:batch_y}\n",
    "            #print(feed_dict)\n",
    "            pp = list_of_csr_to_sparse_tensor(batch_data_adj)\n",
    "            feed_dict = {self.data_x : batch_data_x, self.data_y:batch_y,self.data_adj:list_of_csr_to_sparse_tensor(batch_data_adj)}\n",
    "            learning_rate,loss_average = sess.run([self.op_train,self.op_loss_average],feed_dict)\n",
    "            \n",
    "        #periodical evaluation of the model\n",
    "            epoch = step * self.batch_size / len(train_x)\n",
    "            print('step {} / {} (epoch {:.2f} / {}):'.format(step, num_steps, epoch, self.num_epochs))\n",
    "            print('learning_rate = {:.2e}, loss_average = {:.2e}'.format(learning_rate, loss_average))\n",
    "        \n",
    "            if step % self.eval_frequency == 0 or step == num_steps:\n",
    "                print(\"===========================================================\")\n",
    "                #epoch = step * self.batch_size / len(train_x)\n",
    "                #print('step {} / {} (epoch {:.2f} / {}):'.format(step, num_steps, epoch, self.num_epochs))\n",
    "                #print('learning_rate = {:.2e}, loss_average = {:.2e}'.format(learning_rate, loss_average))\n",
    "                #string, loss = self.evaluate(val_x,val_adj,val_y,sess)\n",
    "                #losses.append(mse)\n",
    "                #print(' validation {}'.format(string))\n",
    "                print(' time: {:.0f}s(wall{:.0f})s'.format(time.process_time() - t_process, time.time() - t_wall))\n",
    "\n",
    "                #Summaries for tensorboard\n",
    "                summary = tf.Summary()\n",
    "                #summary.ParseFromString(sess.run(self.op_summary, feed_dict))\n",
    "                #summary.value.add(tag='validation/loss', simple_value=loss)\n",
    "                writer.add_summary(summary, step)\n",
    "\n",
    "                #save model parameters for evaluation\n",
    "                self.op_saver.save(sess,path,global_step = step)\n",
    "        #print('validation mse: smallest = {:.2f}, mean={:.2f}'.format(min(losses),np.mean(mse[-10:])))\n",
    "        \n",
    "        writer.close()\n",
    "        sess.close()\n",
    "        \n",
    "        t_step = (time.time() - t_wall) / num_steps\n",
    "        return losses, t_step\n",
    "            \n",
    "            \n",
    "    def evaluate(self, data_x,adj, data_y, sess = None):\n",
    "        #return mse and loss\n",
    "        t_process, t_wall = time.process_time(), time.time()\n",
    "        predictions, loss = self.predict(data_x, adj, data_y, sess)\n",
    "        mse = tf.square(prediction - data_y)\n",
    "        mse = tf.reduce_mean(mse)\n",
    "        string = 'mse: {:.2f}'.format(mse)\n",
    "        if sess is None:\n",
    "            string += '\\ntime: {:.0f}s (wall {:.0f}s)'.format(time.process_time()-t_process, time.time()-t_wall)\n",
    "        return string,mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    \n",
    "    def predict(self, data_x, data_adj, data_y = None, sess = None):\n",
    "        loss = 0\n",
    "        size = data_x.shape[0]\n",
    "        predictions = np.empty(size)\n",
    "        sess = self._get_session(sess)\n",
    "        for begin in range(0,size,self.batch_size):\n",
    "            end = begin + self.batch_size\n",
    "            end = min([end,size])\n",
    "            \n",
    "            batch_data_x = np.zeros((self.batch_size, data_x.shape[1]))\n",
    "            batch_data_adj = np.zeros((self.batch_size, data_adj.shape[1], data_adj.shape[2]))\n",
    "            tmp_data_x = data_x[begin:end,:]\n",
    "            tmp_data_adj = data_adj[begin:end,:]\n",
    "            #convert sparse matrices\n",
    "            if type(tmp_data) is not np.ndarray():\n",
    "                tmp_data = tmp.data.toarray()\n",
    "            batch_data_x[:end - begin] = tmp_data_x\n",
    "            batch_data_adj[:end- begin] = tmp_data_adj\n",
    "            print('predict feed_dict:batch_data_x{},batch_data_adj{}'.format(batch_data_x.shape,batch_data_adj.shape))\n",
    "            feed_dict = {self.data_x: batch_data_x,self.data_adj:list_of_csr_to_sparse_tensor(batch_data_adj)}\n",
    "            \n",
    "            #compute the loss\n",
    "            if data_y is not None:\n",
    "                batch_y = np.zeros(self.batch_size)\n",
    "                batch_y[:end-begin] = data_y[begin:end]\n",
    "                feed_dict[self.data_y] = batch_y\n",
    "                batch_pred, batch_loss = sess.run([self.op_prediction, self.op_loss],feed_dict)\n",
    "                loss += batch_loss\n",
    "            else:\n",
    "                batch_pred = sess.run(self.op_prediction, feed_dict)\n",
    "            predictions[begin:end] = batch_pred[:end-begin]\n",
    "            \n",
    "        if labels is not None:\n",
    "            return predictions, loss * self.batch_size / size\n",
    "        else:\n",
    "            return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 755,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = len(data_y)\n",
    "n_train = n//2\n",
    "n_val = n//2\n",
    "X_train = XXX[:n_train]\n",
    "X_val = XXX[n_train:n_train+n_val]\n",
    "X_test = XXX[n_train+n_val:]\n",
    "\n",
    "y_train = data_y[:n_train]\n",
    "y_val = data_y[n_train:n_train+n_val]\n",
    "y_test = data_y[n_train+n_val:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-6.95067959e-02],\n",
       "       [-6.75699032e-02],\n",
       "       [-6.55081576e-02],\n",
       "       [-7.51170405e-02],\n",
       "       [-1.13446175e-01],\n",
       "       [-6.55081576e-02],\n",
       "       [-6.55081576e-02],\n",
       "       [-6.55081576e-02],\n",
       "       [-6.55081576e-02],\n",
       "       [-2.38986127e-01],\n",
       "       [-3.58640775e-01],\n",
       "       [-3.90086418e-01],\n",
       "       [-4.31917753e-01],\n",
       "       [-3.91039991e-01],\n",
       "       [-3.87131737e-01],\n",
       "       [-3.79232710e-01],\n",
       "       [-3.70303970e-01],\n",
       "       [-3.70303970e-01],\n",
       "       [-3.70303970e-01],\n",
       "       [-3.70303970e-01],\n",
       "       [-3.70303970e-01],\n",
       "       [-3.70303970e-01],\n",
       "       [-3.56471529e-01],\n",
       "       [-2.56439278e-01],\n",
       "       [-2.53585352e-01],\n",
       "       [-2.53585352e-01],\n",
       "       [-2.38144723e-01],\n",
       "       [-2.13261144e-01],\n",
       "       [-1.97766710e-01],\n",
       "       [-1.93222069e-01],\n",
       "       [-1.92284487e-01],\n",
       "       [-1.56299396e-01],\n",
       "       [-1.28330742e-01],\n",
       "       [-8.47838372e-02],\n",
       "       [-2.31302133e-01],\n",
       "       [-2.31302133e-01],\n",
       "       [-2.31302133e-01],\n",
       "       [-2.31302133e-01],\n",
       "       [-2.13105575e-01],\n",
       "       [-2.16162196e-01],\n",
       "       [-1.67485103e-01],\n",
       "       [-1.45633193e-01],\n",
       "       [-1.71834166e-01],\n",
       "       [-2.19155898e-01],\n",
       "       [-2.19155898e-01],\n",
       "       [-2.19155898e-01],\n",
       "       [ 3.85180202e+00],\n",
       "       [ 6.49456005e+00],\n",
       "       [ 1.88164232e+00],\n",
       "       [ 1.02845761e-01],\n",
       "       [-3.73289660e-02],\n",
       "       [-1.55023561e-02],\n",
       "       [-3.71494617e-02],\n",
       "       [-1.71307127e-02],\n",
       "       [-1.65339189e-02],\n",
       "       [-3.33704252e-03],\n",
       "       [-6.49265092e-02],\n",
       "       [-1.02786307e-01],\n",
       "       [-1.19205462e-01],\n",
       "       [-1.57066045e-01],\n",
       "       [-3.42871753e-01],\n",
       "       [-3.42871753e-01],\n",
       "       [-3.38114167e-01],\n",
       "       [-2.62914585e-01]])"
      ]
     },
     "execution_count": 756,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myparams = dict()\n",
    "myparams['num_epochs'] = 1\n",
    "myparams['batch_size'] = 1\n",
    "myparams['eval_frequency'] = 5\n",
    "#architecture\n",
    "myparams['F'] = 1\n",
    "myparams['K'] = 3\n",
    "myparams['M'] = 64 #output dimensionality of fully connected layers\n",
    "#Optimization\n",
    "myparams['learning_rate'] = 1e-5\n",
    "myparams['decay_rate'] = 0.95\n",
    "myparams['momentum'] = 0.9\n",
    "myparams['decay_steps'] = n_train/myparams['batch_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([[-0.51785735],\n",
       "         [-0.51746651],\n",
       "         [-0.51705047],\n",
       "         ...,\n",
       "         [-0.21716318],\n",
       "         [-0.35141834],\n",
       "         [-0.41109992]]),\n",
       "  <10001x10001 sparse matrix of type '<class 'numpy.float64'>'\n",
       "  \twith 0 stored elements in Compressed Sparse Row format>),\n",
       " (array([[-0.51769603],\n",
       "         [-0.51761428],\n",
       "         [-0.51752726],\n",
       "         ...,\n",
       "         [-0.241952  ],\n",
       "         [-0.38345954],\n",
       "         [-0.45086734]]),\n",
       "  <10001x10001 sparse matrix of type '<class 'numpy.float64'>'\n",
       "  \twith 0 stored elements in Compressed Sparse Row format>),\n",
       " (array([[-0.50220301],\n",
       "         [-0.50166975],\n",
       "         [-0.50110211],\n",
       "         ...,\n",
       "         [-0.15388778],\n",
       "         [-0.31735318],\n",
       "         [-0.4746384 ]]),\n",
       "  <10001x10001 sparse matrix of type '<class 'numpy.float64'>'\n",
       "  \twith 0 stored elements in Compressed Sparse Row format>),\n",
       " (array([[-0.50354047],\n",
       "         [-0.50337874],\n",
       "         [-0.50320658],\n",
       "         ...,\n",
       "         [-0.2256091 ],\n",
       "         [-0.36157199],\n",
       "         [-0.45559733]]),\n",
       "  <10001x10001 sparse matrix of type '<class 'numpy.float64'>'\n",
       "  \twith 0 stored elements in Compressed Sparse Row format>),\n",
       " (array([[-0.49214339],\n",
       "         [-0.49170634],\n",
       "         [-0.49124112],\n",
       "         ...,\n",
       "         [-0.29323046],\n",
       "         [-0.43033538],\n",
       "         [-0.47297545]]),\n",
       "  <10001x10001 sparse matrix of type '<class 'numpy.float64'>'\n",
       "  \twith 0 stored elements in Compressed Sparse Row format>),\n",
       " (array([[-0.48669648],\n",
       "         [-0.48617648],\n",
       "         [-0.48562296],\n",
       "         ...,\n",
       "         [-0.26632556],\n",
       "         [-0.41657405],\n",
       "         [-0.51397318]]),\n",
       "  <10001x10001 sparse matrix of type '<class 'numpy.float64'>'\n",
       "  \twith 0 stored elements in Compressed Sparse Row format>),\n",
       " (array([[-0.49975261],\n",
       "         [-0.49927039],\n",
       "         [-0.49875709],\n",
       "         ...,\n",
       "         [-0.22069869],\n",
       "         [-0.3457087 ],\n",
       "         [-0.29807564]]),\n",
       "  <10001x10001 sparse matrix of type '<class 'numpy.float64'>'\n",
       "  \twith 0 stored elements in Compressed Sparse Row format>),\n",
       " (array([[-0.50334039],\n",
       "         [-0.50294961],\n",
       "         [-0.50253364],\n",
       "         ...,\n",
       "         [-0.25429822],\n",
       "         [-0.42494292],\n",
       "         [-0.46537444]]),\n",
       "  <10001x10001 sparse matrix of type '<class 'numpy.float64'>'\n",
       "  \twith 0 stored elements in Compressed Sparse Row format>),\n",
       " (array([[-0.49563155],\n",
       "         [-0.49505765],\n",
       "         [-0.49444677],\n",
       "         ...,\n",
       "         [-0.23671284],\n",
       "         [-0.39858135],\n",
       "         [-0.47635662]]),\n",
       "  <10001x10001 sparse matrix of type '<class 'numpy.float64'>'\n",
       "  \twith 0 stored elements in Compressed Sparse Row format>),\n",
       " (array([[-0.5013586 ],\n",
       "         [-0.50079511],\n",
       "         [-0.50019529],\n",
       "         ...,\n",
       "         [-0.22853725],\n",
       "         [-0.38338991],\n",
       "         [-0.45544756]]),\n",
       "  <10001x10001 sparse matrix of type '<class 'numpy.float64'>'\n",
       "  \twith 0 stored elements in Compressed Sparse Row format>),\n",
       " (array([[-0.50529785],\n",
       "         [-0.50493364],\n",
       "         [-0.50454595],\n",
       "         ...,\n",
       "         [-0.22678236],\n",
       "         [-0.40997673],\n",
       "         [-0.46893737]]),\n",
       "  <10001x10001 sparse matrix of type '<class 'numpy.float64'>'\n",
       "  \twith 0 stored elements in Compressed Sparse Row format>),\n",
       " (array([[-0.51782092],\n",
       "         [-0.51722852],\n",
       "         [-0.51659794],\n",
       "         ...,\n",
       "         [-0.22836535],\n",
       "         [-0.41913155],\n",
       "         [-0.4982357 ]]),\n",
       "  <10001x10001 sparse matrix of type '<class 'numpy.float64'>'\n",
       "  \twith 0 stored elements in Compressed Sparse Row format>),\n",
       " (array([[-0.52420187],\n",
       "         [-0.52379768],\n",
       "         [-0.52336744],\n",
       "         ...,\n",
       "         [-0.23974538],\n",
       "         [-0.40048054],\n",
       "         [-0.43092771]]),\n",
       "  <10001x10001 sparse matrix of type '<class 'numpy.float64'>'\n",
       "  \twith 0 stored elements in Compressed Sparse Row format>),\n",
       " (array([[-0.51776018],\n",
       "         [-0.51763998],\n",
       "         [-0.51751204],\n",
       "         ...,\n",
       "         [-0.27727567],\n",
       "         [-0.42155852],\n",
       "         [-0.46310652]]),\n",
       "  <10001x10001 sparse matrix of type '<class 'numpy.float64'>'\n",
       "  \twith 0 stored elements in Compressed Sparse Row format>),\n",
       " (array([[-0.51961048],\n",
       "         [-0.51871565],\n",
       "         [-0.51776315],\n",
       "         ...,\n",
       "         [-0.22388144],\n",
       "         [-0.42535747],\n",
       "         [-0.50367067]]),\n",
       "  <10001x10001 sparse matrix of type '<class 'numpy.float64'>'\n",
       "  \twith 0 stored elements in Compressed Sparse Row format>),\n",
       " (array([[-0.52999613],\n",
       "         [-0.5296636 ],\n",
       "         [-0.52930963],\n",
       "         ...,\n",
       "         [-0.30586707],\n",
       "         [-0.41800486],\n",
       "         [-0.45863337]]),\n",
       "  <10001x10001 sparse matrix of type '<class 'numpy.float64'>'\n",
       "  \twith 0 stored elements in Compressed Sparse Row format>),\n",
       " (array([[-0.53575662],\n",
       "         [-0.53566903],\n",
       "         [-0.53557579],\n",
       "         ...,\n",
       "         [-0.22935983],\n",
       "         [-0.45344173],\n",
       "         [-0.49509861]]),\n",
       "  <10001x10001 sparse matrix of type '<class 'numpy.float64'>'\n",
       "  \twith 0 stored elements in Compressed Sparse Row format>),\n",
       " (array([[-0.5109732 ],\n",
       "         [-0.5105332 ],\n",
       "         [-0.51006484],\n",
       "         ...,\n",
       "         [-0.24302155],\n",
       "         [-0.41626166],\n",
       "         [-0.4878172 ]]),\n",
       "  <10001x10001 sparse matrix of type '<class 'numpy.float64'>'\n",
       "  \twith 0 stored elements in Compressed Sparse Row format>),\n",
       " (array([[-0.49978883],\n",
       "         [-0.49897943],\n",
       "         [-0.49811785],\n",
       "         ...,\n",
       "         [-0.23035444],\n",
       "         [-0.40793724],\n",
       "         [-0.46670457]]),\n",
       "  <10001x10001 sparse matrix of type '<class 'numpy.float64'>'\n",
       "  \twith 0 stored elements in Compressed Sparse Row format>),\n",
       " (array([[-0.5334488 ],\n",
       "         [-0.53291416],\n",
       "         [-0.53234505],\n",
       "         ...,\n",
       "         [-0.2308311 ],\n",
       "         [-0.38492997],\n",
       "         [-0.47901675]]),\n",
       "  <10001x10001 sparse matrix of type '<class 'numpy.float64'>'\n",
       "  \twith 0 stored elements in Compressed Sparse Row format>),\n",
       " (array([[-0.54408062],\n",
       "         [-0.54356113],\n",
       "         [-0.54300816],\n",
       "         ...,\n",
       "         [-0.2230561 ],\n",
       "         [-0.41712434],\n",
       "         [-0.486546  ]]),\n",
       "  <10001x10001 sparse matrix of type '<class 'numpy.float64'>'\n",
       "  \twith 0 stored elements in Compressed Sparse Row format>),\n",
       " (array([[-0.53351932],\n",
       "         [-0.53300304],\n",
       "         [-0.53245348],\n",
       "         ...,\n",
       "         [-0.23401603],\n",
       "         [-0.38196887],\n",
       "         [-0.408045  ]]),\n",
       "  <10001x10001 sparse matrix of type '<class 'numpy.float64'>'\n",
       "  \twith 0 stored elements in Compressed Sparse Row format>),\n",
       " (array([[-0.49955648],\n",
       "         [-0.49923837],\n",
       "         [-0.49889976],\n",
       "         ...,\n",
       "         [-0.21141131],\n",
       "         [-0.37071781],\n",
       "         [-0.40294047]]),\n",
       "  <10001x10001 sparse matrix of type '<class 'numpy.float64'>'\n",
       "  \twith 0 stored elements in Compressed Sparse Row format>),\n",
       " (array([[-0.5571191 ],\n",
       "         [-0.55610341],\n",
       "         [-0.55502224],\n",
       "         ...,\n",
       "         [-0.25031358],\n",
       "         [-0.45324749],\n",
       "         [-0.49216269]]),\n",
       "  <10001x10001 sparse matrix of type '<class 'numpy.float64'>'\n",
       "  \twith 0 stored elements in Compressed Sparse Row format>),\n",
       " (array([[-0.55201439],\n",
       "         [-0.5513928 ],\n",
       "         [-0.55073115],\n",
       "         ...,\n",
       "         [-0.27928308],\n",
       "         [-0.42264728],\n",
       "         [-0.44550973]]),\n",
       "  <10001x10001 sparse matrix of type '<class 'numpy.float64'>'\n",
       "  \twith 0 stored elements in Compressed Sparse Row format>),\n",
       " (array([[-0.55365308],\n",
       "         [-0.55318833],\n",
       "         [-0.55269362],\n",
       "         ...,\n",
       "         [-0.24794515],\n",
       "         [-0.44369791],\n",
       "         [-0.46653412]]),\n",
       "  <10001x10001 sparse matrix of type '<class 'numpy.float64'>'\n",
       "  \twith 0 stored elements in Compressed Sparse Row format>),\n",
       " (array([[-0.56240129],\n",
       "         [-0.56154984],\n",
       "         [-0.56064351],\n",
       "         ...,\n",
       "         [-0.19431869],\n",
       "         [-0.42851272],\n",
       "         [-0.44947027]]),\n",
       "  <10001x10001 sparse matrix of type '<class 'numpy.float64'>'\n",
       "  \twith 0 stored elements in Compressed Sparse Row format>),\n",
       " (array([[-0.57620818],\n",
       "         [-0.57554694],\n",
       "         [-0.57484307],\n",
       "         ...,\n",
       "         [-0.24475213],\n",
       "         [-0.42217374],\n",
       "         [-0.44471379]]),\n",
       "  <10001x10001 sparse matrix of type '<class 'numpy.float64'>'\n",
       "  \twith 0 stored elements in Compressed Sparse Row format>),\n",
       " (array([[-0.5818225 ],\n",
       "         [-0.58110402],\n",
       "         [-0.58033922],\n",
       "         ...,\n",
       "         [-0.24936592],\n",
       "         [-0.44736067],\n",
       "         [-0.47066086]]),\n",
       "  <10001x10001 sparse matrix of type '<class 'numpy.float64'>'\n",
       "  \twith 0 stored elements in Compressed Sparse Row format>),\n",
       " (array([[-0.59439915],\n",
       "         [-0.59378499],\n",
       "         [-0.59313124],\n",
       "         ...,\n",
       "         [-0.18401515],\n",
       "         [-0.41520782],\n",
       "         [-0.46189945]]),\n",
       "  <10001x10001 sparse matrix of type '<class 'numpy.float64'>'\n",
       "  \twith 0 stored elements in Compressed Sparse Row format>),\n",
       " (array([[-0.60855032],\n",
       "         [-0.60829677],\n",
       "         [-0.60802688],\n",
       "         ...,\n",
       "         [-0.06577441],\n",
       "         [-0.28598295],\n",
       "         [-0.43411738]]),\n",
       "  <10001x10001 sparse matrix of type '<class 'numpy.float64'>'\n",
       "  \twith 0 stored elements in Compressed Sparse Row format>),\n",
       " (array([[-0.59144435],\n",
       "         [-0.59052137],\n",
       "         [-0.58953889],\n",
       "         ...,\n",
       "         [-0.15196261],\n",
       "         [-0.35463983],\n",
       "         [-0.45799459]]),\n",
       "  <10001x10001 sparse matrix of type '<class 'numpy.float64'>'\n",
       "  \twith 0 stored elements in Compressed Sparse Row format>),\n",
       " (array([[-0.60299191],\n",
       "         [-0.60229577],\n",
       "         [-0.60155476],\n",
       "         ...,\n",
       "         [-0.19205701],\n",
       "         [-0.41996312],\n",
       "         [-0.47568187]]),\n",
       "  <10001x10001 sparse matrix of type '<class 'numpy.float64'>'\n",
       "  \twith 0 stored elements in Compressed Sparse Row format>),\n",
       " (array([[-0.60203093],\n",
       "         [-0.60169949],\n",
       "         [-0.60134669],\n",
       "         ...,\n",
       "         [-0.23429273],\n",
       "         [-0.42654759],\n",
       "         [-0.48332812]]),\n",
       "  <10001x10001 sparse matrix of type '<class 'numpy.float64'>'\n",
       "  \twith 0 stored elements in Compressed Sparse Row format>),\n",
       " (array([[-0.58717607],\n",
       "         [-0.58649859],\n",
       "         [-0.58577744],\n",
       "         ...,\n",
       "         [-0.18806262],\n",
       "         [-0.3807458 ],\n",
       "         [-0.45747324]]),\n",
       "  <10001x10001 sparse matrix of type '<class 'numpy.float64'>'\n",
       "  \twith 0 stored elements in Compressed Sparse Row format>),\n",
       " (array([[-0.59835168],\n",
       "         [-0.5981686 ],\n",
       "         [-0.59797372],\n",
       "         ...,\n",
       "         [ 0.06730834],\n",
       "         [-0.23679191],\n",
       "         [-0.48030902]]),\n",
       "  <10001x10001 sparse matrix of type '<class 'numpy.float64'>'\n",
       "  \twith 0 stored elements in Compressed Sparse Row format>),\n",
       " (array([[-0.57635589],\n",
       "         [-0.57560447],\n",
       "         [-0.57480462],\n",
       "         ...,\n",
       "         [ 0.05617789],\n",
       "         [-0.1894841 ],\n",
       "         [-0.47496273]]),\n",
       "  <10001x10001 sparse matrix of type '<class 'numpy.float64'>'\n",
       "  \twith 0 stored elements in Compressed Sparse Row format>),\n",
       " (array([[-0.58821044],\n",
       "         [-0.58739829],\n",
       "         [-0.58653378],\n",
       "         ...,\n",
       "         [-0.22014237],\n",
       "         [-0.48118551],\n",
       "         [-0.48224671]]),\n",
       "  <10001x10001 sparse matrix of type '<class 'numpy.float64'>'\n",
       "  \twith 0 stored elements in Compressed Sparse Row format>),\n",
       " (array([[-0.56604886],\n",
       "         [-0.5653722 ],\n",
       "         [-0.56465191],\n",
       "         ...,\n",
       "         [-0.24044233],\n",
       "         [-0.47738933],\n",
       "         [-0.46101806]]),\n",
       "  <10001x10001 sparse matrix of type '<class 'numpy.float64'>'\n",
       "  \twith 0 stored elements in Compressed Sparse Row format>),\n",
       " (array([[-0.58627611],\n",
       "         [-0.58595047],\n",
       "         [-0.58560385],\n",
       "         ...,\n",
       "         [-0.27013258],\n",
       "         [-0.44121913],\n",
       "         [-0.45123247]]),\n",
       "  <10001x10001 sparse matrix of type '<class 'numpy.float64'>'\n",
       "  \twith 0 stored elements in Compressed Sparse Row format>),\n",
       " (array([[-0.60933352],\n",
       "         [-0.60917874],\n",
       "         [-0.60901398],\n",
       "         ...,\n",
       "         [-0.16654588],\n",
       "         [-0.40885575],\n",
       "         [-0.39758894]]),\n",
       "  <10001x10001 sparse matrix of type '<class 'numpy.float64'>'\n",
       "  \twith 0 stored elements in Compressed Sparse Row format>),\n",
       " (array([[-0.57181137],\n",
       "         [-0.57164679],\n",
       "         [-0.57147159],\n",
       "         ...,\n",
       "         [-0.17578566],\n",
       "         [-0.45296169],\n",
       "         [-0.50059407]]),\n",
       "  <10001x10001 sparse matrix of type '<class 'numpy.float64'>'\n",
       "  \twith 0 stored elements in Compressed Sparse Row format>),\n",
       " (array([[-0.58508161],\n",
       "         [-0.584466  ],\n",
       "         [-0.58381072],\n",
       "         ...,\n",
       "         [-0.20045075],\n",
       "         [-0.38381191],\n",
       "         [-0.3844086 ]]),\n",
       "  <10001x10001 sparse matrix of type '<class 'numpy.float64'>'\n",
       "  \twith 0 stored elements in Compressed Sparse Row format>),\n",
       " (array([[-0.60369693],\n",
       "         [-0.60313451],\n",
       "         [-0.60253584],\n",
       "         ...,\n",
       "         [-0.13703897],\n",
       "         [-0.37115799],\n",
       "         [-0.45683115]]),\n",
       "  <10001x10001 sparse matrix of type '<class 'numpy.float64'>'\n",
       "  \twith 0 stored elements in Compressed Sparse Row format>),\n",
       " (array([[-0.57956113],\n",
       "         [-0.57900446],\n",
       "         [-0.5784119 ],\n",
       "         ...,\n",
       "         [-0.11043752],\n",
       "         [-0.35892425],\n",
       "         [-0.45620501]]),\n",
       "  <10001x10001 sparse matrix of type '<class 'numpy.float64'>'\n",
       "  \twith 0 stored elements in Compressed Sparse Row format>),\n",
       " (array([[-0.58809721],\n",
       "         [-0.58777088],\n",
       "         [-0.58742351],\n",
       "         ...,\n",
       "         [-0.17961931],\n",
       "         [-0.35605827],\n",
       "         [-0.44884066]]),\n",
       "  <10001x10001 sparse matrix of type '<class 'numpy.float64'>'\n",
       "  \twith 0 stored elements in Compressed Sparse Row format>),\n",
       " (array([[-0.58905453],\n",
       "         [-0.5882794 ],\n",
       "         [-0.58745431],\n",
       "         ...,\n",
       "         [-0.19812394],\n",
       "         [-0.39681611],\n",
       "         [-0.45119335]]),\n",
       "  <10001x10001 sparse matrix of type '<class 'numpy.float64'>'\n",
       "  \twith 0 stored elements in Compressed Sparse Row format>),\n",
       " (array([[-0.58416523],\n",
       "         [-0.58341994],\n",
       "         [-0.58262661],\n",
       "         ...,\n",
       "         [-0.15785385],\n",
       "         [-0.36138054],\n",
       "         [-0.45830271]]),\n",
       "  <10001x10001 sparse matrix of type '<class 'numpy.float64'>'\n",
       "  \twith 0 stored elements in Compressed Sparse Row format>),\n",
       " (array([[-0.59140899],\n",
       "         [-0.59051073],\n",
       "         [-0.58955456],\n",
       "         ...,\n",
       "         [-0.14522902],\n",
       "         [-0.35634782],\n",
       "         [-0.44564804]]),\n",
       "  <10001x10001 sparse matrix of type '<class 'numpy.float64'>'\n",
       "  \twith 0 stored elements in Compressed Sparse Row format>),\n",
       " (array([[-0.60156833],\n",
       "         [-0.60069225],\n",
       "         [-0.5997597 ],\n",
       "         ...,\n",
       "         [-0.11097278],\n",
       "         [-0.29675349],\n",
       "         [-0.3390625 ]]),\n",
       "  <10001x10001 sparse matrix of type '<class 'numpy.float64'>'\n",
       "  \twith 0 stored elements in Compressed Sparse Row format>)]"
      ]
     },
     "execution_count": 656,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Print:0\", shape=(1, 64), dtype=float32) Tensor(\"inputs/data_y:0\", shape=(1, 64), dtype=float32) Tensor(\"loss/mse/Sum:0\", shape=(), dtype=float32)\n",
      "row [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "col [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "row [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "col [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "step 1 / 5 (epoch 0.20 / 1):\n",
      "learning_rate = 1.00e-05, loss_average = 9.06e+01\n",
      "row [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "col [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "row [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "col [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "step 2 / 5 (epoch 0.40 / 1):\n",
      "learning_rate = 1.00e-05, loss_average = 5.75e+01\n",
      "row [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "col [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "row [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "col [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "step 3 / 5 (epoch 0.60 / 1):\n",
      "learning_rate = 1.00e-05, loss_average = 2.85e+01\n",
      "row [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "col [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "row [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "col [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "step 4 / 5 (epoch 0.80 / 1):\n",
      "learning_rate = 1.00e-05, loss_average = -3.94e+00\n",
      "row [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "col [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "row [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "col [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "step 5 / 5 (epoch 1.00 / 1):\n",
      "learning_rate = 1.00e-05, loss_average = -4.45e+01\n",
      "===========================================================\n",
      " time: 0s(wall0)s\n"
     ]
    }
   ],
   "source": [
    "model =  st_cgcnn(**myparams)\n",
    "losses, t_step = model.fit(zip(*X_train), y_train, zip(*X_val), y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### helper function in this page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#help to return the UTC time with given time interval\n",
    "import time\n",
    "def showTime(x):\n",
    "    tt = time.gmtime(x/1000)\n",
    "    t = '{}.{} {}:{}'.format(tt.tm_mon,tt.tm_mday,tt.tm_hour,tt.tm_min)\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#form the Internet usage of each timeInterval\n",
    "#target matrix is naturally the next timeInterval\n",
    "def dataMatrix(timeInt,data,M):\n",
    "    #generate the dataMatrix of Internet over the whole grids of a given timeInt\n",
    "    #data is a pandas dataframe with hierachical index of [grid, time]\n",
    "    m = int(np.sqrt(M))\n",
    "    X = np.zeros((M+1,))\n",
    "    for i in range(1,M+1):\n",
    "        if timeInt in data.loc[i].index:\n",
    "            X[i] = data.loc[i].loc[timeInt]['Internet']\n",
    "    X = X[1:].reshape((m,m))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#preview the internet stength of several time interval\n",
    "def plotInternet(seriesList, nrows, ncols):\n",
    "    assert len(seriesList) == nrows*ncols\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize = (15,3*nrows))\n",
    "    M = 10000\n",
    "    m = int(np.sqrt(M))\n",
    "    n = nrows * ncols\n",
    "    for i,ax in enumerate(axes.flat):\n",
    "        x = dataMatrix(seriesList[i],d)\n",
    "        im = ax.imshow(x,vmin = 0)\n",
    "        #ax.set_title('Interval{}'.format(seriesList[i]))\n",
    "        ax.set_title(showTime(seriesList[i]))\n",
    "        \n",
    "    fig.subplots_adjust(right = 0.8)\n",
    "    cax = fig.add_axes([0.82,0.16,0.02,0.7])\n",
    "    fig.colorbar(im, cax = cax)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#show the pairs that have interaction with each other\n",
    "def showNonzero(interaction):\n",
    "    print('d = |V| = {},k|V| < |E| = {}'.format(10000,interaction.nnz))\n",
    "    plt.spy(interaction,markersize = 2, color = 'blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def showDistribution(interaction):\n",
    "    plt.boxplot(interaction.data,sym = 'r+')\n",
    "    print('variance: ',np.var(interaction.data))\n",
    "    print('mean: ',np.mean(interaction.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def laplacian1(W, normalized = True,sparse = True):\n",
    "        \n",
    "         # Degree matrix.\n",
    "    d = W.sum(axis=0)\n",
    "\n",
    "        # Laplacian matrix.\n",
    "    if not normalized:\n",
    "        D = scipy.sparse.diags(d.A.squeeze(), 0)\n",
    "        L = D - W\n",
    "    else:\n",
    "        d += np.spacing(np.array(0, W.dtype))\n",
    "        d = 1 / np.sqrt(d)\n",
    "        D = scipy.sparse.diags(d.A.squeeze(), 0)\n",
    "        I = scipy.sparse.identity(d.size, dtype=W.dtype)\n",
    "        L = I - D * W * D\n",
    "\n",
    "        # assert np.abs(L - L.T).mean() < 1e-9\n",
    "    assert type(L) is scipy.sparse.csr.csr_matrix\n",
    "    return L\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_dataset(str_time,end_time,data,dir_,nodes = 10000,inter = 600000):\n",
    "    #return data_all data_all\n",
    "    print('making dataset from {}'.format(dir_))\n",
    "    data_x = []\n",
    "    data_adj = []\n",
    "    for timeInterval in range(str_time,end_time+1,inter):\n",
    "        num = inter // 600000\n",
    "        \n",
    "        datax = np.zeros((nodes,1))\n",
    "        adj = scipy.sparse.csr_matrix((nodes+1,nodes+1))\n",
    "\n",
    "        for i in range(num):\n",
    "            datax += dataMatrix(timeInterval+i*600000,data,nodes).reshape(nodes,1)\n",
    "            \n",
    "            fp_ = '{}/{}.npz'.format(dir_,timeInterval+i*600000)\n",
    "\n",
    "            if os.path.exists(fp_):\n",
    "                adj_tmp = load_npz(fp_)\n",
    "            else:\n",
    "                adj_tmp = scipy.sparse.csr_matrix((nodes+1,nodes+1))\n",
    "\n",
    "            adj = adj.toarray()[0:nodes+1][0:nodes+1]\n",
    "            adj = scipy.sparse.csr_matrix(adj)\n",
    "            adj += adj_tmp\n",
    "\n",
    "        adj = adj_to_sym(adj)\n",
    "        adj = laplacian1(adj)\n",
    "        data_x.append(datax)\n",
    "        data_adj.append(adj)\n",
    "\n",
    "    print('finish preparing the dataset....')\n",
    "    return list(zip(data_x,data_adj))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_dataset(str_time,end_time,data,nodes):\n",
    "    #return data_all data_all\n",
    "    data_x = []\n",
    "    data_adj = []\n",
    "    for timeInterval in range(str_time,end_time+1,600000):\n",
    "        test = dataMatrix(timeInterval,data,nodes).reshape(nodes,)\n",
    "        data_x.append(dataMatrix(timeInterval,data,nodes).reshape(nodes,1))\n",
    "        fp_ = 'demo/{}.npz'.format(timeInterval)\n",
    "        if os.path.exists(fp_):\n",
    "            adj = load_npz(fp_)\n",
    "            adj = adj.toarray()[0:nodes][0:nodes]\n",
    "            adj = scipy.sparse.csr_matrix(adj)\n",
    "        else:\n",
    "            adj = scipy.sparse.csr_matrix((nodes+1,nodes+1))\n",
    "        \n",
    "        data_adj.append(adj)\n",
    "    return list(zip(data_x,data_adj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def adj_to_sym(interaction):\n",
    "    adj = interaction.toarray()\n",
    "    adj = adj + adj.T\n",
    "    return scipy.sparse.csr_matrix(adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def laplacian(W, normalized=True):\n",
    "    \"\"\"Return the Laplacian of the weigth matrix.\"\"\"\n",
    "\n",
    "    # Degree matrix.\n",
    "    d = W.sum(axis=0)\n",
    "\n",
    "    # Laplacian matrix.\n",
    "    if not normalized:\n",
    "        D = scipy.sparse.diags(d.A.squeeze(), 0)\n",
    "        L = D - W\n",
    "    else:\n",
    "        d += np.spacing(np.array(0, W.dtype))\n",
    "        d = 1 / np.sqrt(d)\n",
    "        D = scipy.sparse.diags(d.A.squeeze(), 0)\n",
    "        I = scipy.sparse.identity(d.size, dtype=W.dtype)\n",
    "        L = I - D * W * D\n",
    "\n",
    "    # assert np.abs(L - L.T).mean() < 1e-9\n",
    "    #assert type(L) is scipy.sparse.csr.csr_matrix\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.zeros((10,10))\n",
    "a = np.matrix(a)\n",
    "a = scipy.sparse.csr_matrix(a)\n",
    "l = laplacian(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 738,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 739,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = tf.constant([[0.,0.,0.],[0.,0.,0.],[0.,0.,0.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#f = st_cgcnn(F = 1, K = 1, M = 3)\n",
    "L = model.laplacian(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'sub:0' shape=(3, 3) dtype=float32>"
      ]
     },
     "execution_count": 748,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Fetch argument <tf.Tensor 'sub:0' shape=(3, 3) dtype=float32> cannot be interpreted as a Tensor. (Tensor Tensor(\"sub:0\", shape=(3, 3), dtype=float32) is not an element of this graph.)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[0;32m    281\u001b[0m         self._unique_fetches.append(ops.get_default_graph().as_graph_element(\n\u001b[1;32m--> 282\u001b[1;33m             fetch, allow_tensor=True, allow_operation=True))\n\u001b[0m\u001b[0;32m    283\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[1;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[0;32m   3609\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_finalized\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3610\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[1;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[0;32m   3691\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3692\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Tensor %s is not an element of this graph.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3693\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Tensor Tensor(\"sub:0\", shape=(3, 3), dtype=float32) is not an element of this graph.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-751-34d3979ca845>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[1;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[1;32m-> 1120\u001b[1;33m         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\n\u001b[0m\u001b[0;32m   1121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m     \u001b[1;31m# Run request and get response.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[0;32m    425\u001b[0m     \"\"\"\n\u001b[0;32m    426\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 427\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    428\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[1;34m(fetch)\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m           \u001b[0mfetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfetch_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 253\u001b[1;33m           \u001b[1;32mreturn\u001b[0m \u001b[0m_ElementFetchMapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    254\u001b[0m     \u001b[1;31m# Did not find anything.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m     raise TypeError('Fetch argument %r has invalid type %r' % (fetch,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[0;32m    287\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n\u001b[1;32m--> 289\u001b[1;33m                          'Tensor. (%s)' % (fetch, str(e)))\n\u001b[0m\u001b[0;32m    290\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n",
      "\u001b[1;31mValueError\u001b[0m: Fetch argument <tf.Tensor 'sub:0' shape=(3, 3) dtype=float32> cannot be interpreted as a Tensor. (Tensor Tensor(\"sub:0\", shape=(3, 3), dtype=float32) is not an element of this graph.)"
     ]
    }
   ],
   "source": [
    "sess = model._get_session()\n",
    "sess.run(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
